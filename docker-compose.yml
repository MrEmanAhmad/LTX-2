version: '3.8'

# Local development compose - simulates RunPod environment
# Note: GPU passthrough requires nvidia-docker

services:
  orchestrator:
    build:
      context: ./orchestrator
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - RUNPOD_API_KEY=${RUNPOD_API_KEY}
      - WEBHOOK_BASE_URL=http://orchestrator:8000
      - FLUX_ENDPOINT_ID=${FLUX_ENDPOINT_ID}
      - LTX_VIDEO_ENDPOINT_ID=${LTX_VIDEO_ENDPOINT_ID}
      - WAN21_ENDPOINT_ID=${WAN21_ENDPOINT_ID}
      - CODEFORMER_ENDPOINT_ID=${CODEFORMER_ENDPOINT_ID}
      - RIFE_ENDPOINT_ID=${RIFE_ENDPOINT_ID}
      - REALESRGAN_ENDPOINT_ID=${REALESRGAN_ENDPOINT_ID}
    volumes:
      - ./shared:/app/shared:ro
      - runpod-volume:/runpod-volume
    depends_on:
      - redis

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

  # Local handler testing (requires GPU)
  # Uncomment the handler you want to test locally
  
  # flux:
  #   build:
  #     context: ./handlers/flux
  #     dockerfile: Dockerfile
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]
  #   volumes:
  #     - runpod-volume:/runpod-volume
  #     - ./shared:/app/shared:ro

volumes:
  runpod-volume:
  redis-data:
